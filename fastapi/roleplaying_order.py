import google.generativeai as genai


genai.configure(api_key="")

# ë¡¤í”Œë ˆì‰ ì£¼ë¬¸ ë´‡: í•´ì™¸ ì‹ë‹¹ ì£¼ë¬¸ ìƒí™© ì—­í• ê·¹ ì§„í–‰
roleplay_model = genai.GenerativeModel(
    "gemini-2.0-flash",
    system_instruction=(
        "ë‹¹ì‹ ì€ í•´ì™¸ ì‹ë‹¹ì—ì„œ ì£¼ë¬¸í•˜ëŠ” ìƒí™©ì„ ì—­í• ê·¹ìœ¼ë¡œ ì§„í–‰í•˜ëŠ” íŒŒíŠ¸ë„ˆì…ë‹ˆë‹¤. "
        "ì‚¬ìš©ìëŠ” ì†ë‹˜ ì—­í• ì„ ë§¡ì•„ ì£¼ë¬¸ì„ ì‹œì‘í•˜ë©°, ë‹¹ì‹ ì€ ì ì› ì—­í• ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ì‘ë‹µí•´ì£¼ì„¸ìš”. "
        "ëŒ€í™”ëŠ” 'ì‚¬ìš©ì:' ì™€ 'ì ì›:' í˜•ì‹ìœ¼ë¡œ ì´ì–´ê°€ì•¼ í•©ë‹ˆë‹¤."
    )
)

def simulate_order(user_text: str, history: list[str] | None = None) -> tuple[str, list[str]]:
    """
    historyì™€ í•¨ê»˜ ì‚¬ìš©ìì˜ ì£¼ë¬¸ ë¬¸ì¥(user_text)ì„ ë°›ì•„,
    ì ì› ì—­í• ì˜ ì‘ë‹µì„ ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        user_text: ì‚¬ìš©ìì˜ ìµœì‹  ë°œí™”
        history: ì´ì „ ëŒ€í™” ê¸°ë¡ ë¦¬ìŠ¤íŠ¸, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    Returns:
        reply: ëª¨ë¸ì´ ìƒì„±í•œ ì ì› ì‘ë‹µ
        history: ì—…ë°ì´íŠ¸ëœ ëŒ€í™” ê¸°ë¡
    """
    if history is None:
        history = []
    # ì‚¬ìš©ì ë°œí™” ì¶”ê°€
    history.append(f"ì‚¬ìš©ì: {user_text}")
    # ì „ì²´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    prompt = "\n".join(history + ["ì ì›:"])
    # ëª¨ë¸ í˜¸ì¶œ
    response = roleplay_model.generate_content(prompt)
    reply = response.text.strip()
    # ì ì› ì‘ë‹µ ì¶”ê°€
    history.append(f"ì ì›: {reply}")
    return reply, history

if __name__ == "__main__":
    print("ğŸ½ï¸ í•´ì™¸ ì‹ë‹¹ ì£¼ë¬¸ ì—­í• ê·¹ì„ ì‹œì‘í•©ë‹ˆë‹¤. ê·¸ë§Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit' ì…ë ¥í•˜ì„¸ìš”.\n")
    
    while True:
        user_input = input("ì‚¬ìš©ì: ").strip()
        if user_input.lower() in ("exit", "quit"):
            print("ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”! ğŸ‘‹")
            break
        reply, history = simulate_order(user_input)
        print(f"ì ì›: {reply}\n")